{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8c2e861f",
      "metadata": {
        "id": "8c2e861f"
      },
      "source": [
        "# EfficientNet-B0 Experimentation on Cityscapes Dataset for Semantic Segmentation\n",
        "\n",
        "This notebook implements a series of experiments to evaluate and improve the performance of EfficientNet-B0 on the Cityscapes dataset for semantic segmentation.\n",
        "\n",
        "## Overview\n",
        "\n",
        "1. **Baseline Experiment**: Train EfficientNet-B0 with segmentation head\n",
        "2. **Modified Models**:\n",
        "   - Add CBAM (Convolutional Block Attention Module)\n",
        "   - Switch to Mish activation function\n",
        "   - Add DeeplabV3+ segmentation head\n",
        "3. **Comparative Analysis**: Compare and analyze the results across all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mp-en_V4FA7y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp-en_V4FA7y",
        "outputId": "e969803a-3728-4a7f-f7a2-36d19c4916ed"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to a path without spaces\n",
        "drive.mount('/content/drive/')  # Changed the mount point\n",
        "\n",
        "# Construct the path to the datasets directory with spaces\n",
        "datasets_dir = './drive/MyDrive/NTU-AI6103-DEEP-LEARNING-AND-APPLICATIONS/Group-Assignment/datasets/Cityscapes'\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(datasets_dir):\n",
        "    print(f\"Datasets directory found: {datasets_dir}\")\n",
        "else:\n",
        "    print(f\"Datasets directory not found: {datasets_dir}\")\n",
        "    print(\"Please make sure the path is correct and the directory exists in your Google Drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b00a5168",
      "metadata": {
        "id": "b00a5168"
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "First, let's import all necessary libraries for our experiments:\n",
        "\n",
        "- PyTorch and related libraries for deep learning\n",
        "- EfficientNet implementation\n",
        "- Data processing libraries (NumPy, Pandas, etc.)\n",
        "- Visualization and progress tracking tools\n",
        "\n",
        "It also checks CUDA availability to ensure GPU acceleration if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f32665a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f32665a",
        "outputId": "85dbbefc-1809-44d3-d8f4-9c29d63f4818"
      },
      "outputs": [],
      "source": [
        "# Install required dependencies\n",
        "%pip install torch torchvision torchaudio\n",
        "%pip install efficientnet_pytorch\n",
        "%pip install numpy pandas matplotlib\n",
        "%pip install tqdm scikit-learn\n",
        "%pip install jupyter\n",
        "\n",
        "# For CUDA compatibility check\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741a5961",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "741a5961",
        "outputId": "5e38b4a0-3c92-4e09-ab78-1080bbd00910"
      },
      "outputs": [],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3d327b0",
      "metadata": {
        "id": "e3d327b0"
      },
      "source": [
        "## 2. Data Preparation\n",
        "\n",
        "### 2.1 Loading Cityscapes Dataset\n",
        "\n",
        "Here we'll load the Cityscapes dataset from its original directory structure, subsample 1500 images, and create our train/validation/test splits. The Cityscapes dataset is particularly well-suited for segmentation tasks as it provides pixel-level annotations for urban street scenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "109dceec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "109dceec",
        "outputId": "40a1609e-edf8-45e4-aaf7-972d97bf68ec"
      },
      "outputs": [],
      "source": [
        "# Clone the Cityscapes repository if not already present\n",
        "!git clone https://github.com/mcordts/cityscapesScripts.git\n",
        "%pip install -e cityscapesScripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c0bbac9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7c0bbac9",
        "outputId": "84895aae-0eff-4d91-f237-d4fc99b3a50f"
      },
      "outputs": [],
      "source": [
        "# Import Cityscapes helper functions\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Add the cityscapesScripts directory to the Python path\n",
        "cwd = os.getcwd()\n",
        "cityscapes_path = os.path.join(cwd, 'cityscapesScripts')\n",
        "if cityscapes_path not in sys.path:\n",
        "    sys.path.append(cityscapes_path)\n",
        "\n",
        "# Now import the modules\n",
        "from cityscapesscripts.helpers.labels import trainId2label, id2label\n",
        "\n",
        "# Define paths to dataset directories\n",
        "cityscapes_root = './drive/MyDrive/NTU-AI6103-DEEP-LEARNING-AND-APPLICATIONS/Group-Assignment/datasets/Cityscapes'\n",
        "images_dir = os.path.join(cityscapes_root, 'leftImg8bit_trainvaltest', 'leftImg8bit')\n",
        "annotations_dir = os.path.join(cityscapes_root, 'gtFine_trainvaltest', 'gtFine')\n",
        "\n",
        "# Print images_dir and annotations_dir to check if they are formed correctly\n",
        "print(f\"Images directory: {images_dir}\")\n",
        "print(f\"Annotations directory: {annotations_dir}\")\n",
        "\n",
        "# Function to collect image and label pairs from train, val, and test folders\n",
        "def collect_dataset_files():\n",
        "    splits = ['train', 'val', 'test']\n",
        "    datasets = {'train': [], 'val': [], 'test': []}\n",
        "    for split in splits:\n",
        "        split_img_dir = os.path.join(images_dir, split)\n",
        "        split_label_dir = os.path.join(annotations_dir, split)\n",
        "        city_dirs = [d for d in os.listdir(split_img_dir) if os.path.isdir(os.path.join(split_img_dir, d))]\n",
        "        image_paths = []\n",
        "        label_paths = []\n",
        "        for city in city_dirs:\n",
        "            city_img_dir = os.path.join(split_img_dir, city)\n",
        "            city_img_files = glob.glob(os.path.join(city_img_dir, '*_leftImg8bit.png'))\n",
        "            for img_path in city_img_files:\n",
        "                img_name = os.path.basename(img_path)\n",
        "                img_id = img_name.replace('_leftImg8bit.png', '')\n",
        "                label_name = f\"{img_id}_gtFine_labelIds.png\"\n",
        "                label_path = os.path.join(split_label_dir, city, label_name)\n",
        "                if os.path.exists(label_path):\n",
        "                    image_paths.append(img_path)\n",
        "                    label_paths.append(label_path)\n",
        "        datasets[split] = (image_paths, label_paths)\n",
        "    return datasets['train'][0], datasets['train'][1], datasets['val'][0], datasets['val'][1], datasets['test'][0], datasets['test'][1]\n",
        "\n",
        "# Map Cityscapes IDs to train IDs (0â€“18, 255 for void)\n",
        "def map_cityscapes_labels(label):\n",
        "    label_np = np.array(label, dtype=np.uint8)\n",
        "    mapped_label = np.full_like(label_np, 255, dtype=np.uint8)\n",
        "    id_to_trainid = {\n",
        "        7: 0, 8: 1, 11: 2, 12: 3, 13: 4, 17: 5, 19: 6, 20: 7, 21: 8,\n",
        "        22: 9, 23: 10, 24: 11, 25: 12, 26: 13, 27: 14, 28: 15, 31: 16,\n",
        "        32: 17, 33: 18\n",
        "    }\n",
        "    for id_, train_id in id_to_trainid.items():\n",
        "        mapped_label[label_np == id_] = train_id\n",
        "\n",
        "    # # Debug: Print the number of pixels for each class in the first few images\n",
        "    # if random.random() < 0.05:  # Only print for ~5% of images to avoid flooding output\n",
        "    #     unique_values, counts = np.unique(mapped_label, return_counts=True)\n",
        "    #     print(\"Label distribution:\")\n",
        "    #     for val, count in zip(unique_values, counts):\n",
        "    #         class_name = 'void' if val == 255 else trainId2label[val].name\n",
        "    #         print(f\"  Class {val} ({class_name}): {count} pixels\")\n",
        "\n",
        "    return Image.fromarray(mapped_label)\n",
        "\n",
        "# Define dataset class\n",
        "class CityscapesDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_paths, transform=None, target_transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.label_paths = label_paths\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label_path = self.label_paths[idx]\n",
        "        label = Image.open(label_path)\n",
        "        label = map_cityscapes_labels(label)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "            label = label.squeeze(0).long()\n",
        "        return image, label\n",
        "\n",
        "# Collect dataset\n",
        "print(\"Collecting dataset files...\")\n",
        "train_image_paths, train_label_paths, val_image_paths, val_label_paths, test_image_paths, test_label_paths = collect_dataset_files()\n",
        "print(f\"Found {len(train_image_paths)} train pairs, {len(val_image_paths)} val pairs, {len(test_image_paths)} test pairs\")\n",
        "\n",
        "# Define transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((224, 224), scale=(0.5, 1.5)),\n",
        "    transforms.RandomAffine(degrees=10, shear=10),  # Added shear\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.2, hue=0.1),  # Increased brightness\n",
        "    transforms.GaussianBlur(kernel_size=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "test_transform = val_transform\n",
        "\n",
        "target_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.NEAREST),\n",
        "    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CityscapesDataset(train_image_paths, train_label_paths, transform=train_transform, target_transform=target_transform)\n",
        "val_dataset = CityscapesDataset(val_image_paths, val_label_paths, transform=val_transform, target_transform=target_transform)\n",
        "test_dataset = CityscapesDataset(test_image_paths, test_label_paths, transform=test_transform, target_transform=target_transform)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "\n",
        "# Check label distribution in the training dataset\n",
        "def check_label_distribution(dataset, num_samples=5):\n",
        "    print(\"\\nChecking label distribution in dataset...\")\n",
        "    class_counts = np.zeros(20)  # 19 classes + void (255)\n",
        "\n",
        "    for i in range(min(num_samples, len(dataset))):\n",
        "        idx = np.random.randint(len(dataset))\n",
        "        _, label = dataset[idx]\n",
        "        # If label has channel dimension, remove it\n",
        "        if label.dim() == 3 and label.shape[0] == 1:\n",
        "            label = label.squeeze(0)\n",
        "\n",
        "        unique_values, counts = np.unique(label.numpy(), return_counts=True)\n",
        "        print(f\"Image {i+1}/{num_samples} (idx {idx}) - Unique values: {unique_values}\")\n",
        "\n",
        "        for val, count in zip(unique_values, counts):\n",
        "            class_idx = 19 if val == 255 else val  # Store void class (255) at index 19\n",
        "            class_counts[class_idx] += count\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\nClass distribution summary:\")\n",
        "    class_names = [\n",
        "        'road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light',\n",
        "        'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car',\n",
        "        'truck', 'bus', 'train', 'motorcycle', 'bicycle', 'void'\n",
        "    ]\n",
        "\n",
        "    for i in range(20):\n",
        "        if class_counts[i] > 0:\n",
        "            print(f\"Class {i if i < 19 else 255} ({class_names[i]}): {class_counts[i]:.0f} pixels\")\n",
        "\n",
        "# Run the check on training dataset\n",
        "check_label_distribution(train_dataset, num_samples=10)\n",
        "\n",
        "# Show a sample image from the dataset\n",
        "def show_sample(dataset, idx=0):\n",
        "    img, label = dataset[idx]\n",
        "\n",
        "    # Denormalize the image\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
        "    std = torch.tensor([0.229, 0.224, 0.225])\n",
        "    img_denorm = img * std[:, None, None] + mean[:, None, None]\n",
        "\n",
        "    # Create a color-mapped version of the label for better visualization\n",
        "    # Convert label tensor to numpy and ensure it's 2D by squeezing out the channel dimension\n",
        "    label_np = label.squeeze().numpy()  # Remove the channel dimension (1,224,224) -> (224,224)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_denorm.permute(1, 2, 0).numpy())\n",
        "    plt.title('Image')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(label_np, cmap='viridis')  # Add a colormap for better visualization\n",
        "    plt.title('Segmentation Mask')\n",
        "    plt.colorbar()  # Add a colorbar to show the mapping of class IDs to colors\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a random sample from the training dataset\n",
        "show_sample(train_dataset, idx=np.random.randint(len(train_dataset)))\n",
        "\n",
        "# Also visualize a sample from validation and test to ensure everything looks correct\n",
        "show_sample(val_dataset, idx=np.random.randint(len(val_dataset)))\n",
        "show_sample(test_dataset, idx=np.random.randint(len(test_dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24c2fbed",
      "metadata": {
        "id": "24c2fbed"
      },
      "source": [
        "### Setting Up Data Transformations and Loading Dataset\n",
        "\n",
        "This cell configures data preprocessing pipelines for both training and validation/testing:\n",
        "1. Training transforms include data augmentation (flips, rotations, color jitter)\n",
        "2. All images are resized to 224x224 pixels to match EfficientNet-B0's input size\n",
        "3. Images are normalized using ImageNet mean and standard deviation\n",
        "4. Segmentation masks are also resized to 224x224 but using nearest-neighbor interpolation to preserve label values\n",
        "\n",
        "We then load the Cityscapes dataset using our custom dataset class that handles both images and their corresponding segmentation masks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9eef666",
      "metadata": {
        "id": "f9eef666"
      },
      "source": [
        "## 3. Baseline Model: EfficientNet-B0 for Segmentation\n",
        "\n",
        "### Defining the Baseline EfficientNet-B0 Segmentation Model\n",
        "\n",
        "This cell implements our baseline segmentation model by:\n",
        "1. Creating a custom EfficientNetB0Segmentation class that uses the pre-trained model as an encoder\n",
        "2. Adding a decoder network that upsamples features to produce full-resolution segmentation masks\n",
        "3. Setting up the model to output predictions for 19 classes (Cityscapes semantic classes) at each pixel\n",
        "4. Initializing the model and moving it to the appropriate device (GPU if available)\n",
        "5. Setting up the loss function (Cross-Entropy for segmentation), optimizer (SGD with momentum), and learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08d5ea8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c08d5ea8",
        "outputId": "fc5d2e03-432d-411e-ee37-1005c8faeee8"
      },
      "outputs": [],
      "source": [
        "class EfficientNetB0Segmentation(nn.Module):\n",
        "    def __init__(self, num_classes=19):  # Cityscapes has 19 classes with trainId\n",
        "        super(EfficientNetB0Segmentation, self).__init__()\n",
        "        # Load the pre-trained EfficientNet-B0 model as the encoder\n",
        "        self.encoder = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "        # Get the number of features from the last layer\n",
        "        self.encoder_features = self.encoder._fc.in_features\n",
        "\n",
        "        # Remove the classification head\n",
        "        self.encoder._fc = nn.Identity()\n",
        "\n",
        "        # Create a simple decoder for segmentation\n",
        "        self.decoder = nn.Sequential(\n",
        "            # Upsample to get back to input resolution\n",
        "            nn.ConvTranspose2d(self.encoder_features, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, num_classes, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features from the encoder\n",
        "        features = self.encoder.extract_features(x)  # Shape: [B, C, H/32, W/32]\n",
        "\n",
        "        # Pass through decoder to get segmentation map\n",
        "        segmentation_map = self.decoder(features)  # Shape: [B, num_classes, H, W]\n",
        "\n",
        "        # Ensure output size matches input size\n",
        "        if segmentation_map.shape[-2:] != x.shape[-2:]:\n",
        "            segmentation_map = F.interpolate(segmentation_map, size=x.shape[-2:], mode='bilinear', align_corners=True)\n",
        "\n",
        "        return segmentation_map\n",
        "\n",
        "# Initialize the baseline segmentation model\n",
        "baseline_model = EfficientNetB0Segmentation().to(device)\n",
        "\n",
        "# Define loss function and optimizer for segmentation\n",
        "# Ignore index 255 which is the 'ignored' label in Cityscapes\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "optimizer = optim.SGD(baseline_model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64873fcc",
      "metadata": {
        "id": "64873fcc"
      },
      "source": [
        "### Implementing Training and Evaluation Functions\n",
        "\n",
        "This cell defines two essential functions for model training and evaluation in a segmentation task:\n",
        "1. `train_one_epoch`: Handles a complete training cycle for semantic segmentation, including:\n",
        "   - Forward and backward passes through the network\n",
        "   - Gradient computation and parameter updates\n",
        "   - Loss and segmentation metrics tracking (mean IoU, pixel accuracy)\n",
        "2. `evaluate`: Performs model evaluation on validation or test data:\n",
        "   - Forward passes without gradient computation (using `torch.no_grad()`)\n",
        "   - Computes segmentation metrics (mean IoU, pixel accuracy)\n",
        "   - Visual inspection of segmentation quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02d1ab47",
      "metadata": {
        "id": "02d1ab47"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_pixel_acc = 0.0\n",
        "    running_iou = 0.0\n",
        "    processed_data = 0\n",
        "    num_classes = 19  # Cityscapes has 19 classes with trainId (0-18)\n",
        "\n",
        "    # Initialize tensors to track intersection and union for each class\n",
        "    class_intersection = torch.zeros(num_classes).to(device)\n",
        "    class_union = torch.zeros(num_classes).to(device)\n",
        "\n",
        "    # Debug counters\n",
        "    valid_label_count = 0\n",
        "    batch_count = 0\n",
        "\n",
        "    for inputs, labels in tqdm(dataloader, desc=\"Training\"):\n",
        "        batch_count += 1\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        # Label shape debug - before any processing\n",
        "        if batch_count == 1:\n",
        "            print(f\"Original label shape: {labels.shape}, dtype: {labels.dtype}\")\n",
        "            print(f\"Label min: {labels.min()}, max: {labels.max()}, unique: {torch.unique(labels)}\")\n",
        "\n",
        "        # Remove channel dimension for CrossEntropyLoss [B, H, W]\n",
        "        # If labels have shape [B, 1, H, W], squeeze them to [B, H, W]\n",
        "        if labels.dim() == 4 and labels.shape[1] == 1:\n",
        "            labels = labels.squeeze(1)\n",
        "\n",
        "        labels = labels.long().to(device)  # Ensure labels are of type Long\n",
        "\n",
        "        # Label shape debug - after processing\n",
        "        if batch_count == 1:\n",
        "            print(f\"Processed label shape: {labels.shape}, dtype: {labels.dtype}\")\n",
        "            print(f\"Label min: {labels.min()}, max: {labels.max()}\")\n",
        "            print(f\"Label unique values: {torch.unique(labels)}\")\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)  # Shape: [B, num_classes, H, W]\n",
        "\n",
        "        # Debug first batch outputs\n",
        "        if batch_count == 1:\n",
        "            print(f\"Model output shape: {outputs.shape}, dtype: {outputs.dtype}\")\n",
        "\n",
        "        # Compute loss - CrossEntropyLoss expects (N,C,d1,d2...) for input and (N,d1,d2...) for target\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get predictions\n",
        "        _, preds = torch.max(outputs, 1)  # Shape: [B, H, W]\n",
        "\n",
        "        # Calculate pixel accuracy (ignoring void pixels with value 255)\n",
        "        valid_pixels = (labels != 255)  # Create mask for valid pixels\n",
        "        valid_label_count += torch.sum(valid_pixels).item()\n",
        "        correct_pixels = torch.sum((preds == labels) & valid_pixels).item()\n",
        "        total_valid_pixels = torch.sum(valid_pixels).item()\n",
        "        pixel_acc = correct_pixels / (total_valid_pixels + 1e-8)\n",
        "\n",
        "        # Calculate IoU (Intersection over Union) for each class\n",
        "        for cls in range(num_classes):\n",
        "            # For each class, find pixels where prediction is this class\n",
        "            pred_inclass = (preds == cls)\n",
        "            # Find pixels where ground truth is this class\n",
        "            target_inclass = (labels == cls)\n",
        "            # Calculate intersection (pixels that are this class in both pred and target)\n",
        "            intersection = torch.sum(pred_inclass & target_inclass).item()\n",
        "            # Calculate union (pixels that are this class in either pred or target)\n",
        "            union = torch.sum(pred_inclass | target_inclass).item()\n",
        "            # Accumulate for epoch-level metrics\n",
        "            class_intersection[cls] += intersection\n",
        "            class_union[cls] += union\n",
        "\n",
        "        # Calculate batch mean IoU (for tracking only)\n",
        "        batch_intersection = torch.zeros(num_classes).to(device)\n",
        "        batch_union = torch.zeros(num_classes).to(device)\n",
        "        classes_present = []\n",
        "\n",
        "        for cls in range(num_classes):\n",
        "            pred_cls = (preds == cls)\n",
        "            target_cls = (labels == cls)\n",
        "            batch_intersection[cls] = torch.sum(pred_cls & target_cls).item()\n",
        "            batch_union[cls] = torch.sum(pred_cls | target_cls).item()\n",
        "            if torch.sum(target_cls) > 0:\n",
        "                classes_present.append(cls)\n",
        "\n",
        "        # Avoid division by zero with small epsilon\n",
        "        batch_iou = batch_intersection / (batch_union + 1e-8)\n",
        "\n",
        "        # Only consider classes that are present in this batch\n",
        "        valid_classes = (batch_union > 0)\n",
        "        if torch.sum(valid_classes) > 0:\n",
        "            iou = torch.mean(batch_iou[valid_classes]).item()\n",
        "        else:\n",
        "            iou = 0.0\n",
        "\n",
        "        # Update statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_pixel_acc += pixel_acc * inputs.size(0)\n",
        "        running_iou += iou * inputs.size(0)\n",
        "        processed_data += inputs.size(0)\n",
        "\n",
        "        # Debug for first few batches\n",
        "        if batch_count <= 3:\n",
        "            print(f\"Batch {batch_count} - Classes present: {classes_present}\")\n",
        "            print(f\"Batch {batch_count} - pixel_acc: {pixel_acc:.4f}, IoU: {iou:.4f}\")\n",
        "\n",
        "    # Print final debug info\n",
        "    print(f\"Total valid label pixels: {valid_label_count}\")\n",
        "\n",
        "    # Calculate epoch-level metrics\n",
        "    train_loss = running_loss / processed_data\n",
        "    train_pixel_acc = running_pixel_acc / processed_data\n",
        "\n",
        "    # Calculate per-class IoU for the entire epoch (more accurate than batch-wise)\n",
        "    class_iou = class_intersection / (class_union + 1e-8)\n",
        "    # Only consider classes that actually appeared in the dataset\n",
        "    valid_classes = (class_union > 0)\n",
        "\n",
        "    # Map trainId to class names for better interpretability\n",
        "    class_names = [\n",
        "        'road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light',\n",
        "        'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car',\n",
        "        'truck', 'bus', 'train', 'motorcycle', 'bicycle'\n",
        "    ]\n",
        "\n",
        "    # Print per-class IoU with class names\n",
        "    print(\"\\nPer-class IoU:\")\n",
        "    for cls in range(num_classes):\n",
        "        if class_union[cls] > 0:\n",
        "            print(f\"{class_names[cls]}: {class_iou[cls]:.4f}\")\n",
        "\n",
        "    if torch.sum(valid_classes) > 0:\n",
        "        mean_iou = torch.mean(class_iou[valid_classes]).item()\n",
        "    else:\n",
        "        mean_iou = 0.0\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"Valid classes: {torch.sum(valid_classes).item()} out of {num_classes}\")\n",
        "    print(f\"Mean IoU: {mean_iou:.4f}, Train loss: {train_loss:.4f}, Train pixel acc: {train_pixel_acc:.4f}\")\n",
        "\n",
        "    # Return the relevant metrics\n",
        "    return train_loss, train_pixel_acc, mean_iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wB-9JAUvOyU5",
      "metadata": {
        "id": "wB-9JAUvOyU5"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_pixel_acc = 0.0\n",
        "    running_iou = 0.0\n",
        "    processed_data = 0\n",
        "    num_classes = 19  # Cityscapes has 19 classes with trainId\n",
        "\n",
        "    # Initialize tensors to track intersection and union for each class\n",
        "    class_intersection = torch.zeros(num_classes).to(device)\n",
        "    class_union = torch.zeros(num_classes).to(device)\n",
        "\n",
        "    # Map trainId to class names for better interpretability\n",
        "    class_names = [\n",
        "        'road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light',\n",
        "        'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car',\n",
        "        'truck', 'bus', 'train', 'motorcycle', 'bicycle'\n",
        "    ]\n",
        "\n",
        "    batch_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            batch_count += 1\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # Remove channel dimension for CrossEntropyLoss [B, H, W]\n",
        "            # If labels have shape [B, 1, H, W], squeeze them to [B, H, W]\n",
        "            if labels.dim() == 4 and labels.shape[1] == 1:\n",
        "                labels = labels.squeeze(1)\n",
        "\n",
        "            labels = labels.long().to(device)  # Ensure labels are of type Long\n",
        "\n",
        "            # Debug first batch labels and shapes\n",
        "            if batch_count == 1:\n",
        "                print(f\"Label shape: {labels.shape}, dtype: {labels.dtype}\")\n",
        "                print(f\"Label min: {labels.min()}, max: {labels.max()}\")\n",
        "                print(f\"Label unique values: {torch.unique(labels)}\")\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Debug model output shape\n",
        "            if batch_count == 1:\n",
        "                print(f\"Model output shape: {outputs.shape}, dtype: {outputs.dtype}\")\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs, 1)  # Shape: [B, H, W]\n",
        "\n",
        "            # Calculate pixel accuracy (ignoring void pixels with value 255)\n",
        "            valid_pixels = (labels != 255)  # Create mask for valid pixels\n",
        "            correct_pixels = torch.sum((preds == labels) & valid_pixels).item()\n",
        "            total_valid_pixels = torch.sum(valid_pixels).item()\n",
        "            pixel_acc = correct_pixels / (total_valid_pixels + 1e-8)\n",
        "\n",
        "            # Calculate IoU (Intersection over Union) for each class\n",
        "            for cls in range(num_classes):\n",
        "                # For each class, find pixels where prediction is this class\n",
        "                pred_inclass = (preds == cls)\n",
        "                # Find pixels where ground truth is this class\n",
        "                target_inclass = (labels == cls)\n",
        "                # Calculate intersection (pixels that are this class in both pred and target)\n",
        "                intersection = torch.sum(pred_inclass & target_inclass).item()\n",
        "                # Calculate union (pixels that are this class in either pred or target)\n",
        "                union = torch.sum(pred_inclass | target_inclass).item()\n",
        "                # Accumulate for epoch-level metrics\n",
        "                class_intersection[cls] += intersection\n",
        "                class_union[cls] += union\n",
        "\n",
        "            # Calculate batch mean IoU (for tracking only)\n",
        "            batch_iou = torch.zeros(num_classes).to(device)\n",
        "            valid_classes = torch.zeros(num_classes, dtype=torch.bool).to(device)\n",
        "\n",
        "            for cls in range(num_classes):\n",
        "                pred_cls = (preds == cls)\n",
        "                target_cls = (labels == cls)\n",
        "                intersection = torch.sum(pred_cls & target_cls).item()\n",
        "                union = torch.sum(pred_cls | target_cls).item()\n",
        "                if union > 0:\n",
        "                    batch_iou[cls] = intersection / union\n",
        "                    valid_classes[cls] = True\n",
        "\n",
        "            # Only consider classes that are present in this batch\n",
        "            if torch.sum(valid_classes) > 0:\n",
        "                iou = torch.mean(batch_iou[valid_classes]).item()\n",
        "            else:\n",
        "                iou = 0.0\n",
        "\n",
        "            # Update statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_pixel_acc += pixel_acc * inputs.size(0)\n",
        "            running_iou += iou * inputs.size(0)\n",
        "            processed_data += inputs.size(0)\n",
        "\n",
        "    # Calculate epoch-level metrics\n",
        "    eval_loss = running_loss / processed_data\n",
        "    eval_pixel_acc = running_pixel_acc / processed_data\n",
        "\n",
        "    # Calculate per-class IoU for the entire evaluation set\n",
        "    class_iou = class_intersection / (class_union + 1e-8)\n",
        "    # Only consider classes that actually appeared in the dataset\n",
        "    valid_classes = (class_union > 0)\n",
        "\n",
        "    # Print per-class IoU with class names\n",
        "    print(\"\\nPer-class IoU:\")\n",
        "    for cls in range(num_classes):\n",
        "        if class_union[cls] > 0:\n",
        "            print(f\"{class_names[cls]}: {class_iou[cls]:.4f}\")\n",
        "\n",
        "    if torch.sum(valid_classes) > 0:\n",
        "        mean_iou = torch.mean(class_iou[valid_classes]).item()\n",
        "    else:\n",
        "        mean_iou = 0.0\n",
        "\n",
        "    print(f\"Valid classes: {torch.sum(valid_classes).item()} out of {num_classes}\")\n",
        "    print(f\"Mean IoU: {mean_iou:.4f}, Eval loss: {eval_loss:.4f}, Pixel acc: {eval_pixel_acc:.4f}\")\n",
        "\n",
        "    return eval_loss, eval_pixel_acc, mean_iou"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaf94513",
      "metadata": {
        "id": "aaf94513"
      },
      "source": [
        "### Complete Model Training Pipeline\n",
        "\n",
        "This cell defines and executes the full training pipeline for semantic segmentation:\n",
        "1. Implements the `train_model` function that orchestrates training over multiple epochs\n",
        "   - Tracks training and validation metrics in a history dictionary\n",
        "   - Implements early stopping to save the best model based on validation IoU\n",
        "   - Adjusts learning rate using the scheduler based on validation loss\n",
        "2. Imports the `copy` module to maintain a copy of the best model weights\n",
        "3. Trains the baseline segmentation model for 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab98fb99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666,
          "referenced_widgets": [
            "5b2a1bbfe09c4bc887247f5f15850e52",
            "579eb249124045b69f263d0b94932b2c",
            "281f2a69e6dc49898c753c425100e0ab",
            "5db915cb04c44a468885392181d715cf",
            "1a42116054584b05be51e47215b23b3d",
            "53f35af39a4a4a7bb04a76f90da455c3",
            "fdab33182583424693359d34fdef64f4",
            "b3609ea13a7b41efb240fd25814843c1",
            "29cb45785d7540a5bc7d8a81b3c68eb4",
            "4c6edd62a5394288803e51df2f06c0bd",
            "e6fe8260c91c4d5683f78d957556b78b"
          ]
        },
        "id": "ab98fb99",
        "outputId": "f846a02b-aca7-4b29-ffa8-76541125af17"
      },
      "outputs": [],
      "source": [
        "# Training loop for baseline model\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_pixel_acc': [],\n",
        "        'train_iou': [],\n",
        "        'val_loss': [],\n",
        "        'val_pixel_acc': [],\n",
        "        'val_iou': []\n",
        "    }\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_iou = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Train phase\n",
        "        train_loss, train_pixel_acc, train_iou = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        print(f'Train Loss: {train_loss:.4f} Pixel Acc: {train_pixel_acc:.4f} IoU: {train_iou:.4f}')\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss, val_pixel_acc, val_iou = evaluate(model, val_loader, criterion, device)\n",
        "        print(f'Val Loss: {val_loss:.4f} Pixel Acc: {val_pixel_acc:.4f} IoU: {val_iou:.4f}')\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Deep copy the model if it's the best\n",
        "        if val_iou > best_iou:\n",
        "            best_iou = val_iou\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            print(f'New best model with IoU: {best_iou:.4f}')\n",
        "\n",
        "        # Update history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_pixel_acc'].append(train_pixel_acc)\n",
        "        history['train_iou'].append(train_iou)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_pixel_acc'].append(val_pixel_acc)\n",
        "        history['val_iou'].append(val_iou)\n",
        "\n",
        "        print()\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n",
        "\n",
        "import copy\n",
        "\n",
        "# Train the baseline segmentation model\n",
        "baseline_model_trained, baseline_history = train_model(\n",
        "    baseline_model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    num_epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d8748f",
      "metadata": {
        "id": "40d8748f"
      },
      "source": [
        "<!-- ### Evaluating the Baseline Model on Test Set\n",
        "\n",
        "This cell evaluates the trained baseline segmentation model on the unseen test data:\n",
        "1. Computes test loss, pixel accuracy, and mean IoU using the previously defined `evaluate` function\n",
        "2. Prints the results to compare with later model variants\n",
        "3. These segmentation-specific metrics provide a comprehensive assessment of how well the model performs at the pixel level -->\n",
        "\n",
        "** Currently we will skip test set **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09aef973",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b5286174cfba4c428505f92b5b5aae29",
            "512f7e394df44d82aed9a340a9b172e2",
            "168d7e49aa6c43f0a08702db5578f6d5",
            "a431c065c3b0410e959589cdb9f6ae1f",
            "8f9d969f6fff4eacae536b61cfc7b245",
            "8d9953cdb5ee402eb723f8b65d653ddc",
            "177f685fecad4578a77089dbe4f2e9c3",
            "7d04c25a84054c4195b266075a5332de",
            "535eb4ccab6243139a33ab80d231a190",
            "dad1464a4b22495e8cec7bc369a1e6cf",
            "f5ce746d5466472e8558bd9a00ee72e2"
          ]
        },
        "id": "09aef973",
        "outputId": "584d1415-0fca-41b8-a14e-1795057edb9f"
      },
      "outputs": [],
      "source": [
        "# # Evaluate the baseline model on test set\n",
        "# baseline_test_loss, baseline_test_pixel_acc, baseline_test_iou = evaluate(baseline_model_trained, test_loader, criterion, device)\n",
        "# print(f'Baseline Model - Test Loss: {baseline_test_loss:.4f} Pixel Acc: {baseline_test_pixel_acc:.4f} IoU: {baseline_test_iou:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d16d5ae",
      "metadata": {
        "id": "3d16d5ae"
      },
      "source": [
        "### Visualizing the Training Results\n",
        "\n",
        "This cell defines and uses a function to visualize training progress for semantic segmentation:\n",
        "1. Creates the `plot_training_history` function that generates three plots:\n",
        "   - Training and validation loss curves\n",
        "   - Training and validation pixel accuracy curves\n",
        "   - Training and validation mean IoU curves\n",
        "2. Visualizes the baseline model's training history to analyze convergence and potential overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f2e6996",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "3f2e6996",
        "outputId": "8cadd24a-97d9-4493-d914-ecde9f484dad"
      },
      "outputs": [],
      "source": [
        "# Visualize the training history\n",
        "def plot_training_history(history, title):\n",
        "    epochs = range(1, len(history['train_loss'])+1)\n",
        "\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(epochs, history['train_loss'], 'bo-', label='Training Loss')\n",
        "    plt.plot(epochs, history['val_loss'], 'ro-', label='Validation Loss')\n",
        "    plt.title(f'{title} - Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(epochs, history['train_pixel_acc'], 'bo-', label='Training Pixel Accuracy')\n",
        "    plt.plot(epochs, history['val_pixel_acc'], 'ro-', label='Validation Pixel Accuracy')\n",
        "    plt.title(f'{title} - Pixel Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Pixel Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(epochs, history['train_iou'], 'bo-', label='Training IoU')\n",
        "    plt.plot(epochs, history['val_iou'], 'ro-', label='Validation IoU')\n",
        "    plt.title(f'{title} - Mean IoU')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Mean IoU')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize baseline model training history\n",
        "plot_training_history(baseline_history, 'Baseline EfficientNet-B0 Segmentation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "561b867a",
      "metadata": {
        "id": "561b867a"
      },
      "source": [
        "## 4. Modified Models\n",
        "\n",
        "### 4.1 EfficientNet-B0 with CBAM (Convolutional Block Attention Module)\n",
        "\n",
        "CBAM enhances the representational power by focusing on important features and suppressing unnecessary ones. For segmentation tasks, this attention mechanism is particularly helpful as it allows the model to focus on relevant spatial regions and feature channels, leading to more accurate pixel-wise predictions.\n",
        "\n",
        "### Implementing the CBAM Attention Module\n",
        "\n",
        "This cell implements the Convolutional Block Attention Module (CBAM) and integrates it with EfficientNet-B0 for segmentation:\n",
        "1. Defines the `ChannelAttention` class that focuses on important channels\n",
        "2. Defines the `SpatialAttention` class that emphasizes informative regions\n",
        "3. Combines both in the `CBAM` class\n",
        "4. Creates an `EfficientNetB0WithCBAM` class that incorporates CBAM into the segmentation model architecture\n",
        "5. Implements a decoder structure to convert encoded features to segmentation masks\n",
        "6. Initializes the model and sets up its optimizer and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c83bc217",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c83bc217",
        "outputId": "2ae0e0bf-d524-498d-e8fb-6e9b7353b114"
      },
      "outputs": [],
      "source": [
        "# Implementing CBAM\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        concat = torch.cat([avg_out, max_out], dim=1)\n",
        "        out = self.conv(concat)\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channel_att = ChannelAttention(in_planes, ratio)\n",
        "        self.spatial_att = SpatialAttention(kernel_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * self.channel_att(x)\n",
        "        x = x * self.spatial_att(x)\n",
        "        return x\n",
        "\n",
        "# EfficientNet-B0 with CBAM attention for segmentation\n",
        "class EfficientNetB0WithCBAM(nn.Module):\n",
        "    def __init__(self, num_classes=19):  # 19 classes for Cityscapes segmentation\n",
        "        super(EfficientNetB0WithCBAM, self).__init__()\n",
        "        # Load the pre-trained EfficientNet-B0 model as encoder\n",
        "        self.encoder = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "        in_features = self.encoder._fc.in_features\n",
        "\n",
        "        # Remove the classification head from the encoder\n",
        "        self.encoder._fc = nn.Identity()\n",
        "\n",
        "        # Add CBAM at the end of feature extraction\n",
        "        self.cbam = CBAM(in_features)\n",
        "\n",
        "        # Create decoder for segmentation (similar to baseline but with CBAM in between)\n",
        "        self.decoder = nn.Sequential(\n",
        "            # Upsample to get back to input resolution\n",
        "            nn.ConvTranspose2d(in_features, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, num_classes, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features from the encoder\n",
        "        features = self.encoder.extract_features(x)  # Shape: [B, C, H/32, W/32]\n",
        "\n",
        "        # Apply CBAM attention\n",
        "        features_with_attention = self.cbam(features)\n",
        "\n",
        "        # Pass through decoder to get segmentation map\n",
        "        segmentation_map = self.decoder(features_with_attention)  # Shape: [B, num_classes, H, W]\n",
        "\n",
        "        # Ensure output size matches input size\n",
        "        if segmentation_map.shape[-2:] != x.shape[-2:]:\n",
        "            segmentation_map = F.interpolate(segmentation_map, size=x.shape[-2:], mode='bilinear', align_corners=True)\n",
        "\n",
        "        return segmentation_map\n",
        "\n",
        "# Initialize the CBAM model\n",
        "cbam_model = EfficientNetB0WithCBAM().to(device)\n",
        "\n",
        "# Define loss function, optimizer and scheduler for the CBAM segmentation model\n",
        "cbam_criterion = nn.CrossEntropyLoss(ignore_index=255)  # Ignore index 255 which is the 'ignored' label in Cityscapes\n",
        "cbam_optimizer = optim.SGD(cbam_model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "cbam_scheduler = optim.lr_scheduler.ReduceLROnPlateau(cbam_optimizer, 'min', patience=3, factor=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac43af07",
      "metadata": {
        "id": "ac43af07"
      },
      "source": [
        "### Training and Evaluating the CBAM Segmentation Model\n",
        "\n",
        "Here we train and evaluate the EfficientNet-B0 model enhanced with CBAM for semantic segmentation:\n",
        "1. Train the model for 10 epochs using the same training function as the baseline\n",
        "2. Track segmentation metrics (mean IoU, pixel accuracy) during training\n",
        "3. Visualize the training history to compare with the baseline segmentation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b00cefa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631,
          "referenced_widgets": [
            "a7900dc7ac224826842debfc3ed9b033",
            "5804399b13b84d3289c20ab9a89316a0",
            "b07681019231474ab03dafe5e98ad94a",
            "80b8c937565c478ba33f25c65e09412b",
            "bff4100912df404bbef776fb5bc71078",
            "42fe12dbe58f4ef49da6ae2a12f732cc",
            "4c934458a9f249e5b585b6e9809a0edb",
            "6b5e702a7295430c9adb6f4fb9d90dbc",
            "837befb197114970983ec6481c541dfc",
            "8913e9e243ce40588a19cbe7d30f4159",
            "96adf7fe1f5e45eb82597519bf402724"
          ]
        },
        "id": "b00cefa5",
        "outputId": "2cb76ad9-0fc6-466b-f2e0-3a31240d015b"
      },
      "outputs": [],
      "source": [
        "# Train the CBAM segmentation model\n",
        "cbam_model_trained, cbam_history = train_model(\n",
        "    cbam_model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    cbam_criterion,\n",
        "    cbam_optimizer,\n",
        "    cbam_scheduler,\n",
        "    num_epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wt66JKOT-b-3",
      "metadata": {
        "id": "wt66JKOT-b-3"
      },
      "outputs": [],
      "source": [
        "# # Evaluate CBAM model on test set\n",
        "# cbam_test_loss, cbam_test_pixel_acc, cbam_test_iou = evaluate(cbam_model_trained, test_loader, cbam_criterion, device)\n",
        "# print(f'CBAM Model - Test Loss: {cbam_test_loss:.4f} Pixel Acc: {cbam_test_pixel_acc:.4f} IoU: {cbam_test_iou:.4f}')\n",
        "\n",
        "# Visualize CBAM model training history\n",
        "plot_training_history(cbam_history, 'EfficientNet-B0 with CBAM for Segmentation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00279e84",
      "metadata": {
        "id": "00279e84"
      },
      "source": [
        "### Detailed Training History Analysis for CBAM vs Baseline Segmentation\n",
        "\n",
        "This cell creates a comprehensive DataFrame containing the epoch-by-epoch segmentation metrics for both models:\n",
        "1. Collects per-epoch training and validation losses\n",
        "2. Collects per-epoch training and validation IoU and pixel accuracy values\n",
        "3. Organizes data into a DataFrame for detailed analysis\n",
        "\n",
        "This information enables us to pinpoint exactly when and how the CBAM model's segmentation performance diverges from the baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cda7d945",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "cda7d945",
        "outputId": "3d301786-1bc5-48d8-e90e-c99bfba3db39"
      },
      "outputs": [],
      "source": [
        "# Log epoch-wise training metrics for comparative analysis\n",
        "epochs = list(range(1, len(baseline_history['train_loss'])+1))\n",
        "\n",
        "train_data = {\n",
        "    'Epoch': epochs,\n",
        "    'Baseline Train Loss': baseline_history['train_loss'],\n",
        "    'Baseline Val Loss': baseline_history['val_loss'],\n",
        "    'CBAM Train Loss': cbam_history['train_loss'],\n",
        "    'CBAM Val Loss': cbam_history['val_loss'],\n",
        "    'Baseline Train IoU': baseline_history['train_iou'],\n",
        "    'Baseline Val IoU': baseline_history['val_iou'],\n",
        "    'CBAM Train IoU': cbam_history['train_iou'],\n",
        "    'CBAM Val IoU': cbam_history['val_iou'],\n",
        "    'Baseline Train Pixel Acc': baseline_history['train_pixel_acc'],\n",
        "    'Baseline Val Pixel Acc': baseline_history['val_pixel_acc'],\n",
        "    'CBAM Train Pixel Acc': cbam_history['train_pixel_acc'],\n",
        "    'CBAM Val Pixel Acc': cbam_history['val_pixel_acc']\n",
        "}\n",
        "\n",
        "training_df = pd.DataFrame(train_data)\n",
        "print(\"Training History Comparison for Segmentation:\")\n",
        "display(training_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "668a4aec",
      "metadata": {
        "id": "668a4aec"
      },
      "source": [
        "### 4.2 EfficientNet-B0 with Mish Activation Function for Segmentation\n",
        "\n",
        "Mish is a self-regularized non-monotonic activation function that often outperforms ReLU and its variants in various tasks. For semantic segmentation, Mish may provide better gradient flow characteristics that improve feature representation at pixel level.\n",
        "\n",
        "### Implementing the Mish Activation Function for Segmentation\n",
        "\n",
        "This cell implements the Mish activation function and integrates it with EfficientNet-B0 for segmentation:\n",
        "1. Defines the `Mish` activation class (formula: x * tanh(softplus(x)))\n",
        "2. Creates an `EfficientNetB0WithMish` class that replaces all ReLU activations with Mish\n",
        "3. Implements a recursive function to replace activations throughout the model\n",
        "4. Adds a segmentation decoder to produce pixel-wise predictions\n",
        "5. Initializes the model and sets up its optimizer and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac37e7ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac37e7ec",
        "outputId": "a140366b-c215-40ad-dea2-bae496efca56"
      },
      "outputs": [],
      "source": [
        "# Implementing Mish activation\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "# Updating the EfficientNetB0WithMish class to fix the channel mismatch\n",
        "class EfficientNetB0WithMish(nn.Module):\n",
        "    def __init__(self, num_classes=19):  # 19 classes for Cityscapes segmentation\n",
        "        super(EfficientNetB0WithMish, self).__init__()\n",
        "        # Load the pre-trained EfficientNet-B0 model as encoder\n",
        "        self.efficient_net = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "        # Get the correct number of features from the encoder\n",
        "        self.in_features = self.efficient_net._fc.in_features  # This should be 1280 for EfficientNet-B0\n",
        "\n",
        "        # Replace all activation functions with Mish\n",
        "        self._replace_relu_with_mish(self.efficient_net)\n",
        "\n",
        "        # Decoder structure with correct channel sizes\n",
        "        self.decoder = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(self.in_features, 256, kernel_size=4, stride=2, padding=1),\n",
        "                nn.BatchNorm2d(256),\n",
        "                Mish(),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "                nn.BatchNorm2d(128),\n",
        "                Mish(),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                Mish(),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                Mish(),\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # Final segmentation head\n",
        "        self.segmentation_head = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            Mish(),\n",
        "            nn.Conv2d(32, num_classes, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def _replace_relu_with_mish(self, model):\n",
        "        for name, module in model.named_children():\n",
        "            if isinstance(module, nn.ReLU):\n",
        "                setattr(model, name, Mish())\n",
        "            else:\n",
        "                self._replace_relu_with_mish(module)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Original input size for later upsampling\n",
        "        input_size = x.size()[2:]\n",
        "\n",
        "        # Extract features from the EfficientNet backbone\n",
        "        features = self.efficient_net.extract_features(x)  # Output shape: [B, 1280, H/32, W/32]\n",
        "\n",
        "        # Apply decoder blocks\n",
        "        x = features\n",
        "        for decoder_block in self.decoder:\n",
        "            x = decoder_block(x)\n",
        "\n",
        "        # Apply final segmentation head\n",
        "        x = self.segmentation_head(x)\n",
        "\n",
        "        # Upsample to match original input size if needed\n",
        "        if x.shape[-2:] != input_size:\n",
        "            x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Initialize the Mish model for segmentation\n",
        "mish_model = EfficientNetB0WithMish(num_classes=19).to(device)\n",
        "\n",
        "# Define optimizer for Mish segmentation model\n",
        "mish_optimizer = optim.SGD(mish_model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "mish_scheduler = optim.lr_scheduler.ReduceLROnPlateau(mish_optimizer, 'min', patience=3, factor=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc0e605",
      "metadata": {
        "id": "9cc0e605"
      },
      "source": [
        "### Training and Evaluating the Mish Model for Segmentation\n",
        "\n",
        "Here we train and evaluate the EfficientNet-B0 model with Mish activation functions for semantic segmentation:\n",
        "1. Train the model for 10 epochs using the same training function as before\n",
        "2. Evaluate its performance on the test set using segmentation metrics (mIoU, pixel accuracy)\n",
        "3. Visualize the training history and sample segmentation outputs to analyze the impact of the Mish activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2611dce2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "76a611ba6306484786e269fa142f91ef",
            "4995d778d74142ec9af51df0f789a2e2",
            "6d9ca3f19a7f44a9a74c350688c88466",
            "04a6e2bf1f8d4e6e9e28ba3d255fde27",
            "d5fa52c4eeef4f5388503d6247d33bf1",
            "beb6b2b0c5cd4d2fbbd92eb897579c62",
            "f22f7faddae9412483d88d0b98c3fc1b",
            "d55f24a80cdc4cf3a1fff84665a38bfd",
            "107d725ad327479c884a0c684bf03cbc",
            "54e206f4a34449118379dd75a7cf4d2d",
            "0c8f24c9dd834f0ab7935914aeee8283"
          ]
        },
        "id": "2611dce2",
        "outputId": "2d7c491d-0555-4786-a049-821284c0630e"
      },
      "outputs": [],
      "source": [
        "# Train the Mish segmentation model\n",
        "mish_model_trained, mish_history = train_model(\n",
        "    mish_model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    mish_optimizer,\n",
        "    mish_scheduler,\n",
        "    num_epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XqaF5nJhisGN",
      "metadata": {
        "id": "XqaF5nJhisGN"
      },
      "outputs": [],
      "source": [
        "# Visualize Mish model training history for segmentation\n",
        "plot_training_history(mish_history, 'EfficientNet-B0 with Mish for Segmentation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1444d6d1",
      "metadata": {
        "id": "1444d6d1"
      },
      "source": [
        "### Detailed Training History Analysis for Mish vs Baseline\n",
        "\n",
        "This cell creates a comprehensive DataFrame of epoch-by-epoch training metrics:\n",
        "1. Compares training and validation losses between Mish and baseline models\n",
        "2. Compares training and validation accuracies between the models\n",
        "3. Allows for fine-grained analysis of how Mish affects the training dynamics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e4e11c",
      "metadata": {
        "id": "83e4e11c"
      },
      "outputs": [],
      "source": [
        "# Log epoch-wise training metrics for comparative analysis\n",
        "epochs = list(range(1, len(baseline_history['train_loss'])+1))\n",
        "\n",
        "train_data = {\n",
        "    'Epoch': epochs,\n",
        "    'Baseline Train Loss': baseline_history['train_loss'],\n",
        "    'Baseline Val Loss': baseline_history['val_loss'],\n",
        "    'Mish Train Loss': mish_history['train_loss'],\n",
        "    'Mish Val Loss': mish_history['val_loss'],\n",
        "    'Baseline Train Acc': baseline_history['train_acc'],\n",
        "    'Baseline Val Acc': baseline_history['val_acc'],\n",
        "    'Mish Train Acc': mish_history['train_acc'],\n",
        "    'Mish Val Acc': mish_history['val_acc']\n",
        "}\n",
        "\n",
        "training_df = pd.DataFrame(train_data)\n",
        "print(\"Training History Comparison (Baseline vs Mish):\")\n",
        "display(training_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "885c65b4",
      "metadata": {
        "id": "885c65b4"
      },
      "source": [
        "### 4.3 EfficientNet-B0 with DeeplabV3+ Segmentation Head\n",
        "\n",
        "DeepLabV3+ is a semantic segmentation architecture that combines atrous convolution with encoder-decoder structure.\n",
        "\n",
        "### Implementing DeepLabV3+ Segmentation Head\n",
        "\n",
        "This cell implements the DeepLabV3+ architecture with EfficientNet-B0 as the backbone:\n",
        "1. Creates the `ASPP` (Atrous Spatial Pyramid Pooling) module that captures multi-scale information\n",
        "   - Uses multiple dilated convolutions with different rates\n",
        "   - Includes global pooling to capture context\n",
        "2. Implements the `DeepLabV3Plus` class that combines:\n",
        "   - EfficientNet backbone for feature extraction\n",
        "   - ASPP module for multi-scale processing\n",
        "   - Decoder for generating the final segmentation output\n",
        "3. Initializes the model and sets up optimizer and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4340582d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4340582d",
        "outputId": "ec041a1a-5338-4012-c897-4285d8752be0"
      },
      "outputs": [],
      "source": [
        "# Implementing DeeplabV3+ segmentation head\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, rates=[6, 12, 18]):\n",
        "        super(ASPP, self).__init__()\n",
        "\n",
        "        self.aspp = nn.ModuleList()\n",
        "\n",
        "        # 1x1 convolution\n",
        "        self.aspp.append(nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        ))\n",
        "\n",
        "        # Atrous convolutions\n",
        "        for rate in rates:\n",
        "            self.aspp.append(nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 3, padding=rate, dilation=rate, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU()\n",
        "            ))\n",
        "\n",
        "        # Global average pooling\n",
        "        self.global_avg_pool = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Output layer\n",
        "        self.output = nn.Sequential(\n",
        "            nn.Conv2d(out_channels * (len(rates) + 2), out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        size = x.size()[2:]\n",
        "\n",
        "        outputs = []\n",
        "        for module in self.aspp:\n",
        "            outputs.append(module(x))\n",
        "\n",
        "        # Process global average pooling branch\n",
        "        gap_output = self.global_avg_pool(x)\n",
        "        gap_output = F.interpolate(gap_output, size=size, mode='bilinear', align_corners=True)\n",
        "        outputs.append(gap_output)\n",
        "\n",
        "        # Concatenate and process through output layer\n",
        "        x = torch.cat(outputs, dim=1)\n",
        "        return self.output(x)\n",
        "\n",
        "class DeepLabV3Plus(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=19, output_stride=16):\n",
        "        super(DeepLabV3Plus, self).__init__()\n",
        "        self.backbone = base_model\n",
        "        in_features = self.backbone._fc.in_features\n",
        "\n",
        "        # Remove the classification head\n",
        "        self.backbone._fc = nn.Identity()\n",
        "\n",
        "        # Low-level features from earlier layers for skip connection\n",
        "        self.low_level_features = 64  # Adjust based on EfficientNet architecture\n",
        "\n",
        "        # ASPP module\n",
        "        self.aspp = ASPP(in_features, 256)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, num_classes, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        input_size = x.size()[2:]\n",
        "\n",
        "        # Extract features\n",
        "        features = self.backbone.extract_features(x)\n",
        "\n",
        "        # Apply ASPP\n",
        "        x = self.aspp(features)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        # Upsampling to original size\n",
        "        x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=True)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Initialize the DeepLabV3+ model for segmentation\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "deeplabv3_model = DeepLabV3Plus(base_model, num_classes=19).to(device)  # 19 classes for Cityscapes\n",
        "\n",
        "# Define loss function and optimizer for semantic segmentation\n",
        "deeplabv3_criterion = nn.CrossEntropyLoss(ignore_index=255)  # Ignore index 255 which is the 'ignored' label in Cityscapes\n",
        "deeplabv3_optimizer = optim.SGD(deeplabv3_model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "deeplabv3_scheduler = optim.lr_scheduler.ReduceLROnPlateau(deeplabv3_optimizer, 'min', patience=3, factor=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb2077f0",
      "metadata": {
        "id": "bb2077f0"
      },
      "source": [
        "### Training and Evaluating the DeepLabV3+ Model\n",
        "\n",
        "Here we train and evaluate the EfficientNet-B0 model with DeepLabV3+ segmentation head:\n",
        "1. Train the model for 10 epochs using the same training function\n",
        "2. Evaluate its performance on the test set\n",
        "3. Visualize the training history to analyze how the segmentation head affects performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2415bae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "888f6e5995ec4868ad83be701df6364e",
            "8590a72a20d94fbb83b1c107f32bde5f",
            "c0d9bad3c0c9410fabe98811fdfbe056",
            "cb5a790a245c4298a4e5b02fd09e9676",
            "55ab945365484913bf7e549e988e7a99",
            "7cd46dc5127e418ea61a466b89859e30",
            "b661f87a905f403691c3c8719958522c",
            "7a341f042c7b4eed92ca7c677c718a8e",
            "8762d59431f14e25b97a46265e248c73",
            "e3717c0c1ad64ee5867ec7c5066e8b61",
            "d193d54911254c04b9a74299f77e275b"
          ]
        },
        "id": "c2415bae",
        "outputId": "87b25896-464e-430f-ce45-705e241af23b"
      },
      "outputs": [],
      "source": [
        "# Train the DeepLabV3+ segmentation model\n",
        "deeplabv3_model_trained, deeplabv3_history = train_model(\n",
        "    deeplabv3_model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    deeplabv3_criterion,\n",
        "    deeplabv3_optimizer,\n",
        "    deeplabv3_scheduler,\n",
        "    num_epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iIU_9tVvij7L",
      "metadata": {
        "id": "iIU_9tVvij7L"
      },
      "outputs": [],
      "source": [
        "# Visualize DeepLabV3+ model training history for segmentation\n",
        "plot_training_history(deeplabv3_history, 'EfficientNet-B0 with DeepLabV3+ for Segmentation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90087f54",
      "metadata": {
        "id": "90087f54"
      },
      "source": [
        "### Detailed Training History Analysis for DeepLabV3+ vs Baseline\n",
        "\n",
        "This cell creates a comprehensive comparison of training metrics between models:\n",
        "1. Collects epoch-by-epoch training and validation losses\n",
        "2. Collects epoch-by-epoch training and validation accuracies\n",
        "3. Organizes the data into a DataFrame for detailed analysis\n",
        "\n",
        "This information helps identify how the DeepLabV3+ architecture changes learning dynamics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2b39f6",
      "metadata": {
        "id": "3c2b39f6"
      },
      "outputs": [],
      "source": [
        "# Log epoch-wise training metrics for comparative analysis\n",
        "epochs = list(range(1, len(baseline_history['train_loss'])+1))\n",
        "\n",
        "train_data = {\n",
        "    'Epoch': epochs,\n",
        "    'Baseline Train Loss': baseline_history['train_loss'],\n",
        "    'Baseline Val Loss': baseline_history['val_loss'],\n",
        "    'DeeplabV3+ Train Loss': deeplabv3_history['train_loss'],\n",
        "    'DeeplabV3+ Val Loss': deeplabv3_history['val_loss'],\n",
        "    'Baseline Train Acc': baseline_history['train_acc'],\n",
        "    'Baseline Val Acc': baseline_history['val_acc'],\n",
        "    'DeeplabV3+ Train Acc': deeplabv3_history['train_acc'],\n",
        "    'DeeplabV3+ Val Acc': deeplabv3_history['val_acc']\n",
        "}\n",
        "\n",
        "training_df = pd.DataFrame(train_data)\n",
        "print(\"Training History Comparison (Baseline vs DeeplabV3+):\")\n",
        "display(training_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27ac3aaa",
      "metadata": {},
      "source": [
        "### 4.4 Combined Approach: EfficientNet-B0 with CBAM, Mish, and DeepLabV3+\n",
        "\n",
        "After testing each modification individually, we now explore combining all three enhancements:\n",
        "1. CBAM for attention-based feature refinement\n",
        "2. Mish activation function for better gradient flow\n",
        "3. DeepLabV3+ segmentation head for multi-scale feature extraction\n",
        "\n",
        "This combined approach should theoretically leverage the strengths of each individual modification to achieve even better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aa942dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combined model: EfficientNet-B0 with CBAM, Mish, and DeepLabV3+\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, num_classes=19):  # 19 classes for Cityscapes segmentation\n",
        "        super(CombinedModel, self).__init__()\n",
        "        # Initialize the EfficientNet-B0 backbone\n",
        "        self.efficient_net = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "        self.in_features = self.efficient_net._fc.in_features  # Should be 1280 for EfficientNet-B0\n",
        "\n",
        "        # Remove the classification head\n",
        "        self.efficient_net._fc = nn.Identity()\n",
        "\n",
        "        # Replace ReLU with Mish in the backbone\n",
        "        self._replace_relu_with_mish(self.efficient_net)\n",
        "\n",
        "        # Add CBAM module\n",
        "        self.cbam = CBAM(self.in_features)\n",
        "\n",
        "        # Add ASPP module (from DeepLabV3+)\n",
        "        self.aspp = ASPP(self.in_features, 256)\n",
        "\n",
        "        # Add decoder (from DeepLabV3+ but with Mish activation)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            Mish(),  # Using Mish instead of ReLU\n",
        "            nn.Conv2d(256, 256, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            Mish(),  # Using Mish instead of ReLU\n",
        "            nn.Conv2d(256, num_classes, 1)\n",
        "        )\n",
        "\n",
        "    def _replace_relu_with_mish(self, model):\n",
        "        for name, module in model.named_children():\n",
        "            if isinstance(module, nn.ReLU):\n",
        "                setattr(model, name, Mish())\n",
        "            else:\n",
        "                self._replace_relu_with_mish(module)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Store input size for later upsampling\n",
        "        input_size = x.size()[2:]\n",
        "\n",
        "        # Extract features from EfficientNet backbone\n",
        "        features = self.efficient_net.extract_features(x)  # [B, 1280, H/32, W/32]\n",
        "\n",
        "        # Apply CBAM attention\n",
        "        features_with_attention = self.cbam(features)\n",
        "\n",
        "        # Apply ASPP module from DeepLabV3+\n",
        "        x = self.aspp(features_with_attention)\n",
        "\n",
        "        # Apply decoder\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        # Upsampling to original size\n",
        "        x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=True)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Initialize the combined model\n",
        "combined_model = CombinedModel(num_classes=19).to(device)  # 19 classes for Cityscapes\n",
        "\n",
        "# Define loss function, optimizer and scheduler for the combined segmentation model\n",
        "combined_criterion = nn.CrossEntropyLoss(ignore_index=255)  # Ignore index 255 which is the 'ignored' label in Cityscapes\n",
        "combined_optimizer = optim.SGD(combined_model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "combined_scheduler = optim.lr_scheduler.ReduceLROnPlateau(combined_optimizer, 'min', patience=3, factor=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1a97ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the combined segmentation model\n",
        "combined_model_trained, combined_history = train_model(\n",
        "    combined_model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    combined_criterion,\n",
        "    combined_optimizer,\n",
        "    combined_scheduler,\n",
        "    num_epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df808b3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize combined model training history for segmentation\n",
        "plot_training_history(combined_history, 'EfficientNet-B0 with CBAM, Mish, and DeepLabV3+ for Segmentation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3261bb23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Log epoch-wise training metrics for segmentation comparative analysis\n",
        "epochs = list(range(1, len(baseline_history['train_loss'])+1))\n",
        "\n",
        "train_data = {\n",
        "    'Epoch': epochs,\n",
        "    'Baseline Train Loss': baseline_history['train_loss'],\n",
        "    'Baseline Val Loss': baseline_history['val_loss'],\n",
        "    'Combined Train Loss': combined_history['train_loss'],\n",
        "    'Combined Val Loss': combined_history['val_loss'],\n",
        "    'Baseline Train IoU': baseline_history['train_iou'],\n",
        "    'Baseline Val IoU': baseline_history['val_iou'],\n",
        "    'Combined Train IoU': combined_history['train_iou'],\n",
        "    'Combined Val IoU': combined_history['val_iou'],\n",
        "    'Baseline Train Pixel Acc': baseline_history['train_pixel_acc'],\n",
        "    'Baseline Val Pixel Acc': baseline_history['val_pixel_acc'],\n",
        "    'Combined Train Pixel Acc': combined_history['train_pixel_acc'],\n",
        "    'Combined Val Pixel Acc': combined_history['val_pixel_acc']\n",
        "}\n",
        "\n",
        "training_df = pd.DataFrame(train_data)\n",
        "print(\"Training History Comparison for Segmentation (Baseline vs Combined):\")\n",
        "display(training_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a98617d2",
      "metadata": {
        "id": "a98617d2"
      },
      "source": [
        "## 5. Results Comparison and Analysis\n",
        "\n",
        "Let's compare the performance of all model variants across various metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "055032d5",
      "metadata": {
        "id": "055032d5"
      },
      "source": [
        "### Save the experiments results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4852ac51",
      "metadata": {
        "id": "4852ac51"
      },
      "source": [
        "### Setting Up Model Storage\n",
        "\n",
        "This cell prepares a directory to save our trained segmentation models:\n",
        "1. Creates a 'models' directory in the current working directory if it doesn't exist\n",
        "2. Displays the path where models will be saved\n",
        "\n",
        "Saving models allows us to use them later for inference without retraining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9af1a02a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9af1a02a",
        "outputId": "2c8cc27e-6b81-495f-e6b0-8ada37b9b714"
      },
      "outputs": [],
      "source": [
        "# Create a models directory if it doesn't exist\n",
        "import os\n",
        "models_dir = os.path.join(os.getcwd(), 'models')\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "print(f\"Models will be saved to: {models_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da9adebc",
      "metadata": {
        "id": "da9adebc"
      },
      "source": [
        "### Saving the Baseline Segmentation Model\n",
        "\n",
        "This cell saves the trained baseline segmentation model to disk:\n",
        "1. Defines the file path for the baseline model\n",
        "2. Saves a comprehensive checkpoint including:\n",
        "   - Model state dictionary (weights and parameters)\n",
        "   - Optimizer state\n",
        "   - Training history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6830ec4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6830ec4c",
        "outputId": "0587d597-8a17-42a0-9da2-5fcd8b65897c"
      },
      "outputs": [],
      "source": [
        "# Save the baseline segmentation model after test evaluation\n",
        "baseline_model_path = os.path.join(models_dir, 'baseline_efficientnet_b0_segmentation.pth')\n",
        "torch.save({\n",
        "    'model_state_dict': baseline_model_trained.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'history': baseline_history,\n",
        "}, baseline_model_path)\n",
        "print(f\"Baseline segmentation model saved to {baseline_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b575d712",
      "metadata": {
        "id": "b575d712"
      },
      "source": [
        "### Loading the Baseline Segmentation Model\n",
        "\n",
        "This cell defines a function to load the saved baseline segmentation model and demonstrates its usage:\n",
        "1. Implements the `load_baseline_model` function that:\n",
        "   - Initializes a fresh model with the same architecture\n",
        "   - Loads the weights and state from the saved checkpoint\n",
        "   - Returns the model along with its history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e82837c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e82837c6",
        "outputId": "4c340981-f67d-42cd-8981-abeeb575f7e0"
      },
      "outputs": [],
      "source": [
        "# Load the baseline segmentation model\n",
        "def load_baseline_model(model_path):\n",
        "    model = EfficientNetB0Segmentation().to(device)\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    history = checkpoint['history']\n",
        "    print(f\"Loaded baseline segmentation model.\")\n",
        "    return model, history\n",
        "\n",
        "baseline_model_path = os.path.join(models_dir, 'baseline_efficientnet_b0_segmentation.pth')\n",
        "baseline_model_trained, baseline_history = load_baseline_model(baseline_model_path)\n",
        "# The loaded model can now be used for inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "270c742f",
      "metadata": {
        "id": "270c742f"
      },
      "source": [
        "### Saving the CBAM Model\n",
        "\n",
        "This cell saves the trained CBAM model to disk:\n",
        "1. Defines the file path for the CBAM model\n",
        "2. Saves a comprehensive checkpoint including:\n",
        "   - Model state dictionary\n",
        "   - Optimizer state\n",
        "   - Training history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6294a8dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6294a8dc",
        "outputId": "88ce904d-05fc-49d3-c75b-bddcf5fa5dc3"
      },
      "outputs": [],
      "source": [
        "# Save the CBAM model after test evaluation\n",
        "cbam_model_path = os.path.join(models_dir, 'cbam_efficientnet_b0.pth')\n",
        "torch.save({\n",
        "    'model_state_dict': cbam_model_trained.state_dict(),\n",
        "    'optimizer_state_dict': cbam_optimizer.state_dict(),\n",
        "    'history': cbam_history,\n",
        "}, cbam_model_path)\n",
        "print(f\"CBAM model saved to {cbam_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d56bfd0",
      "metadata": {
        "id": "8d56bfd0"
      },
      "source": [
        "### Loading the CBAM Model\n",
        "\n",
        "This cell defines a function to load the saved CBAM model:\n",
        "1. Implements the `load_cbam_model` function with the same pattern as the baseline loader\n",
        "2. Properly initializes the CBAM-specific architecture before loading weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c0e382",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49c0e382",
        "outputId": "733896bf-094f-4070-af14-e434d619c8aa"
      },
      "outputs": [],
      "source": [
        "# Load the CBAM model\n",
        "def load_cbam_model(model_path):\n",
        "    model = EfficientNetB0WithCBAM().to(device)\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    history = checkpoint['history']\n",
        "    print(f\"Loaded CBAM segmentation model.\")\n",
        "    return model, history\n",
        "\n",
        "cbam_model_path = os.path.join(models_dir, 'cbam_efficientnet_b0.pth')\n",
        "# Example usage:\n",
        "cbam_model_trained, cbam_history = load_cbam_model(cbam_model_path)\n",
        "# The loaded model can now be used for inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5418a88f",
      "metadata": {
        "id": "5418a88f"
      },
      "source": [
        "### Saving the Mish Model\n",
        "\n",
        "This cell saves the trained Mish model to disk:\n",
        "1. Defines the file path for the Mish model\n",
        "2. Saves the complete checkpoint with model weights, optimizer state and history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d216d7eb",
      "metadata": {
        "id": "d216d7eb"
      },
      "outputs": [],
      "source": [
        "# Save the Mish model after test evaluation\n",
        "mish_model_path = os.path.join(models_dir, 'mish_efficientnet_b0.pth')\n",
        "torch.save({\n",
        "    'model_state_dict': mish_model_trained.state_dict(),\n",
        "    'optimizer_state_dict': mish_optimizer.state_dict(),\n",
        "    'history': mish_history,\n",
        "}, mish_model_path)\n",
        "print(f\"Mish model saved to {mish_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d497e396",
      "metadata": {
        "id": "d497e396"
      },
      "source": [
        "### Loading the Mish Model\n",
        "\n",
        "This cell defines a function to load the saved Mish model:\n",
        "1. Implements the `load_mish_model` function that correctly initializes the model with Mish activations\n",
        "2. Loads the saved weights and states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d68e28",
      "metadata": {
        "id": "e6d68e28"
      },
      "outputs": [],
      "source": [
        "# Load the Mish model\n",
        "def load_mish_model(model_path):\n",
        "    model = EfficientNetB0WithMish().to(device)\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    history = checkpoint['history']\n",
        "    # test_acc = checkpoint['test_acc']\n",
        "    # test_loss = checkpoint['test_loss']\n",
        "    print(f\"Loaded Mish segmentation model.\")\n",
        "    return model, history\n",
        "\n",
        "# Example usage:\n",
        "loaded_mish_model, loaded_mish_history = load_mish_model(mish_model_path)\n",
        "# The loaded model can now be used for inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6871a586",
      "metadata": {
        "id": "6871a586"
      },
      "source": [
        "### Saving the DeepLabV3+ Model\n",
        "\n",
        "This cell saves the trained DeepLabV3+ model to disk:\n",
        "1. Defines the file path for the DeepLabV3+ model\n",
        "2. Saves the complete checkpoint with all necessary information\n",
        "3. Confirms successful saving with a print statement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50020ef7",
      "metadata": {
        "id": "50020ef7"
      },
      "outputs": [],
      "source": [
        "# Save the DeeplabV3+ model after test evaluation\n",
        "deeplabv3_model_path = os.path.join(models_dir, 'deeplabv3_efficientnet_b0.pth')\n",
        "torch.save({\n",
        "    'model_state_dict': deeplabv3_model_trained.state_dict(),\n",
        "    'optimizer_state_dict': deeplabv3_optimizer.state_dict(),\n",
        "    'history': deeplabv3_history\n",
        "}, deeplabv3_model_path)\n",
        "print(f\"DeeplabV3+ model saved to {deeplabv3_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4509ff98",
      "metadata": {
        "id": "4509ff98"
      },
      "source": [
        "### Loading the DeepLabV3+ Model\n",
        "\n",
        "This cell defines a function to load the saved DeepLabV3+ model:\n",
        "1. Implements the `load_deeplabv3_model` function with special handling for the two-component architecture:\n",
        "   - First initializes a fresh EfficientNet-B0 base model\n",
        "   - Then creates the DeepLabV3+ model with that base\n",
        "   - Loads the saved weights and states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bafe165f",
      "metadata": {
        "id": "bafe165f"
      },
      "outputs": [],
      "source": [
        "# Load the DeeplabV3+ model\n",
        "def load_deeplabv3_model(model_path):\n",
        "    base_model = EfficientNet.from_pretrained('efficientnet-b0')  # We need a base model for DeeplabV3+\n",
        "    model = DeepLabV3Plus(base_model).to(device)\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    history = checkpoint['history']\n",
        "    print(f\"Loaded DeeplabV3+ model.\")\n",
        "    return model, history\n",
        "\n",
        "# Example usage:\n",
        "loaded_deeplabv3_model, loaded_deeplabv3_history = load_deeplabv3_model(deeplabv3_model_path)\n",
        "# The loaded model can now be used for inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44028095",
      "metadata": {},
      "source": [
        "### Saving the Combined Model\n",
        "\n",
        "This cell saves the trained combined model to disk:\n",
        "1. Defines the file path for the combined model\n",
        "2. Saves a comprehensive checkpoint including model weights, optimizer state, history\n",
        "3. Confirms successful saving with a print statement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d337737",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the combined model after test evaluation\n",
        "combined_model_path = os.path.join(models_dir, 'combined_model_efficientnet_b0.pth')\n",
        "torch.save({\n",
        "    'model_state_dict': combined_model_trained.state_dict(),\n",
        "    'optimizer_state_dict': combined_optimizer.state_dict(),\n",
        "    'history': combined_history,\n",
        "}, combined_model_path)\n",
        "print(f\"Combined model saved to {combined_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c8712a0",
      "metadata": {},
      "source": [
        "### Loading the Combined Model\n",
        "\n",
        "This cell defines a function to load the saved combined model:\n",
        "1. Implements the `load_combined_model` function that initializes the architecture with all modifications\n",
        "2. Loads the saved weights and states\n",
        "3. Provides an example of loading the model for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e4d7ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the combined model\n",
        "def load_combined_model(model_path):\n",
        "    model = CombinedModel().to(device)\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    history = checkpoint['history']\n",
        "    print(f\"Loaded combined model.\")\n",
        "    return model, history, test_acc, test_loss\n",
        "\n",
        "# Example usage:\n",
        "loaded_combined_model, loaded_combined_history = load_combined_model(combined_model_path)\n",
        "# The loaded model can now be used for inference"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "008b78bdf04f460db1237fa9cf35dde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e0b14711b6146c7b8e51cd85c7e1cb5",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e80e472a80904be98acafe8c137eb72e",
            "value": 7
          }
        },
        "04a6e2bf1f8d4e6e9e28ba3d255fde27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54e206f4a34449118379dd75a7cf4d2d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0c8f24c9dd834f0ab7935914aeee8283",
            "value": "â€‡1/744â€‡[00:05&lt;47:02,â€‡â€‡3.80s/it]"
          }
        },
        "0c8f24c9dd834f0ab7935914aeee8283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "107d725ad327479c884a0c684bf03cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10a31ef38b7f428589e2e83c6c7634cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53f84f762db2416ca5714208e34d94b7",
            "max": 744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e26910625fde4ecebd928b6f0997e594",
            "value": 1
          }
        },
        "168d7e49aa6c43f0a08702db5578f6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d04c25a84054c4195b266075a5332de",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_535eb4ccab6243139a33ab80d231a190",
            "value": 7
          }
        },
        "177f685fecad4578a77089dbe4f2e9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a42116054584b05be51e47215b23b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c90adf275445bf8d190d51c6bda958": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281f2a69e6dc49898c753c425100e0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3609ea13a7b41efb240fd25814843c1",
            "max": 744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29cb45785d7540a5bc7d8a81b3c68eb4",
            "value": 100
          }
        },
        "29cb45785d7540a5bc7d8a81b3c68eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2adf883fc33c4f1f9993bf6f1699d814": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddf14b4154d04b45bc3abc7fa9509a29",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c20b4213bb264c9ba383c37c2b2d62f2",
            "value": "Training:â€‡â€‡â€‡0%"
          }
        },
        "35ee3269c3f4433cb13fe824da2cf2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42fe12dbe58f4ef49da6ae2a12f732cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4433182d2b23483f8bc4db2494f44ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4995d778d74142ec9af51df0f789a2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beb6b2b0c5cd4d2fbbd92eb897579c62",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f22f7faddae9412483d88d0b98c3fc1b",
            "value": "Training:â€‡â€‡â€‡0%"
          }
        },
        "4c6edd62a5394288803e51df2f06c0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c934458a9f249e5b585b6e9809a0edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "512f7e394df44d82aed9a340a9b172e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d9953cdb5ee402eb723f8b65d653ddc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_177f685fecad4578a77089dbe4f2e9c3",
            "value": "Evaluating:â€‡100%"
          }
        },
        "535eb4ccab6243139a33ab80d231a190": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53f35af39a4a4a7bb04a76f90da455c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f84f762db2416ca5714208e34d94b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e206f4a34449118379dd75a7cf4d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ab945365484913bf7e549e988e7a99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "579eb249124045b69f263d0b94932b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53f35af39a4a4a7bb04a76f90da455c3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fdab33182583424693359d34fdef64f4",
            "value": "Training:â€‡â€‡â€‡8%"
          }
        },
        "5804399b13b84d3289c20ab9a89316a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42fe12dbe58f4ef49da6ae2a12f732cc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4c934458a9f249e5b585b6e9809a0edb",
            "value": "Training:â€‡â€‡â€‡0%"
          }
        },
        "5b2a1bbfe09c4bc887247f5f15850e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_579eb249124045b69f263d0b94932b2c",
              "IPY_MODEL_281f2a69e6dc49898c753c425100e0ab",
              "IPY_MODEL_5db915cb04c44a468885392181d715cf"
            ],
            "layout": "IPY_MODEL_1a42116054584b05be51e47215b23b3d"
          }
        },
        "5db915cb04c44a468885392181d715cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c6edd62a5394288803e51df2f06c0bd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e6fe8260c91c4d5683f78d957556b78b",
            "value": "â€‡100/744â€‡[05:56&lt;32:03,â€‡â€‡2.99s/it]"
          }
        },
        "5e60b196fbd742fa8fdd002961b42816": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5facc15893a84a35b1fdef021222bdaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2adf883fc33c4f1f9993bf6f1699d814",
              "IPY_MODEL_10a31ef38b7f428589e2e83c6c7634cc",
              "IPY_MODEL_bb94ef797c2d4c24b7abe9603c166758"
            ],
            "layout": "IPY_MODEL_fc5d66d247314e019247d1717c01fbf1"
          }
        },
        "62a5968a280c413399bc75de94366469": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6580e083c7154fccb0d1aaefc8c8827d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b5e702a7295430c9adb6f4fb9d90dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d9ca3f19a7f44a9a74c350688c88466": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55f24a80cdc4cf3a1fff84665a38bfd",
            "max": 744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_107d725ad327479c884a0c684bf03cbc",
            "value": 1
          }
        },
        "76a611ba6306484786e269fa142f91ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4995d778d74142ec9af51df0f789a2e2",
              "IPY_MODEL_6d9ca3f19a7f44a9a74c350688c88466",
              "IPY_MODEL_04a6e2bf1f8d4e6e9e28ba3d255fde27"
            ],
            "layout": "IPY_MODEL_d5fa52c4eeef4f5388503d6247d33bf1"
          }
        },
        "78dc837c969d4541ad6f991544bfad7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a341f042c7b4eed92ca7c677c718a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd46dc5127e418ea61a466b89859e30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d04c25a84054c4195b266075a5332de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b8c937565c478ba33f25c65e09412b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8913e9e243ce40588a19cbe7d30f4159",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_96adf7fe1f5e45eb82597519bf402724",
            "value": "â€‡2/744â€‡[00:09&lt;48:35,â€‡â€‡3.93s/it]"
          }
        },
        "82b387426f8b4e828cadda08ffc24ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff3feeb9a34f49e18694615448126891",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_62a5968a280c413399bc75de94366469",
            "value": "â€‡7/7â€‡[00:10&lt;00:00,â€‡â€‡1.28s/it]"
          }
        },
        "837befb197114970983ec6481c541dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "844a2d08db7a4827bf6f3c60d8147219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6580e083c7154fccb0d1aaefc8c8827d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_35ee3269c3f4433cb13fe824da2cf2a9",
            "value": "â€‡7/7â€‡[00:10&lt;00:00,â€‡â€‡1.29s/it]"
          }
        },
        "8590a72a20d94fbb83b1c107f32bde5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd46dc5127e418ea61a466b89859e30",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b661f87a905f403691c3c8719958522c",
            "value": "Training:â€‡â€‡â€‡0%"
          }
        },
        "8762d59431f14e25b97a46265e248c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "888f6e5995ec4868ad83be701df6364e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8590a72a20d94fbb83b1c107f32bde5f",
              "IPY_MODEL_c0d9bad3c0c9410fabe98811fdfbe056",
              "IPY_MODEL_cb5a790a245c4298a4e5b02fd09e9676"
            ],
            "layout": "IPY_MODEL_55ab945365484913bf7e549e988e7a99"
          }
        },
        "8913e9e243ce40588a19cbe7d30f4159": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a57cf5cb6d043eda860d92b9b46b27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d9953cdb5ee402eb723f8b65d653ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f9d969f6fff4eacae536b61cfc7b245": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96adf7fe1f5e45eb82597519bf402724": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98d896e089984d8490de453660cceda7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e0b14711b6146c7b8e51cd85c7e1cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3ee78303a21452098d8a77bdc5b7fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98d896e089984d8490de453660cceda7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4433182d2b23483f8bc4db2494f44ccd",
            "value": "Computingâ€‡IoU:â€‡100%"
          }
        },
        "a431c065c3b0410e959589cdb9f6ae1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dad1464a4b22495e8cec7bc369a1e6cf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f5ce746d5466472e8558bd9a00ee72e2",
            "value": "â€‡7/7â€‡[00:10&lt;00:00,â€‡â€‡1.28s/it]"
          }
        },
        "a7900dc7ac224826842debfc3ed9b033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5804399b13b84d3289c20ab9a89316a0",
              "IPY_MODEL_b07681019231474ab03dafe5e98ad94a",
              "IPY_MODEL_80b8c937565c478ba33f25c65e09412b"
            ],
            "layout": "IPY_MODEL_bff4100912df404bbef776fb5bc71078"
          }
        },
        "b07681019231474ab03dafe5e98ad94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b5e702a7295430c9adb6f4fb9d90dbc",
            "max": 744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_837befb197114970983ec6481c541dfc",
            "value": 2
          }
        },
        "b3609ea13a7b41efb240fd25814843c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5286174cfba4c428505f92b5b5aae29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_512f7e394df44d82aed9a340a9b172e2",
              "IPY_MODEL_168d7e49aa6c43f0a08702db5578f6d5",
              "IPY_MODEL_a431c065c3b0410e959589cdb9f6ae1f"
            ],
            "layout": "IPY_MODEL_8f9d969f6fff4eacae536b61cfc7b245"
          }
        },
        "b661f87a905f403691c3c8719958522c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7b7a5d89658476ba115f701eeefd02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba68aa2c59124c5ebbd6111791906301",
              "IPY_MODEL_008b78bdf04f460db1237fa9cf35dde0",
              "IPY_MODEL_844a2d08db7a4827bf6f3c60d8147219"
            ],
            "layout": "IPY_MODEL_c906d2fab1454c32a2ce2efc0fca13b7"
          }
        },
        "b99c9157e1ef4a8aa8d18e691da4d158": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba68aa2c59124c5ebbd6111791906301": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc57cfa3ea8f48eab57c70d91c05f2c4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8a57cf5cb6d043eda860d92b9b46b27b",
            "value": "Computingâ€‡IoU:â€‡100%"
          }
        },
        "bb94ef797c2d4c24b7abe9603c166758": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b99c9157e1ef4a8aa8d18e691da4d158",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fd2bab845abe4cd0b3374ab8c40c2e7a",
            "value": "â€‡1/744â€‡[00:04&lt;32:07,â€‡â€‡2.59s/it]"
          }
        },
        "bc57cfa3ea8f48eab57c70d91c05f2c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb6b2b0c5cd4d2fbbd92eb897579c62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bff4100912df404bbef776fb5bc71078": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d9bad3c0c9410fabe98811fdfbe056": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a341f042c7b4eed92ca7c677c718a8e",
            "max": 744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8762d59431f14e25b97a46265e248c73",
            "value": 1
          }
        },
        "c20b4213bb264c9ba383c37c2b2d62f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c906d2fab1454c32a2ce2efc0fca13b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb5a790a245c4298a4e5b02fd09e9676": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3717c0c1ad64ee5867ec7c5066e8b61",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d193d54911254c04b9a74299f77e275b",
            "value": "â€‡1/744â€‡[00:06&lt;46:19,â€‡â€‡3.74s/it]"
          }
        },
        "d193d54911254c04b9a74299f77e275b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d55f24a80cdc4cf3a1fff84665a38bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5fa52c4eeef4f5388503d6247d33bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad1464a4b22495e8cec7bc369a1e6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2837a451b34eefa0a322f6ae0094e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e60b196fbd742fa8fdd002961b42816",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78dc837c969d4541ad6f991544bfad7c",
            "value": 7
          }
        },
        "ddf14b4154d04b45bc3abc7fa9509a29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e26910625fde4ecebd928b6f0997e594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3717c0c1ad64ee5867ec7c5066e8b61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6fe8260c91c4d5683f78d957556b78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e80e472a80904be98acafe8c137eb72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e85d369c14d042598322b8c80eecdbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3ee78303a21452098d8a77bdc5b7fa5",
              "IPY_MODEL_dd2837a451b34eefa0a322f6ae0094e8",
              "IPY_MODEL_82b387426f8b4e828cadda08ffc24ca7"
            ],
            "layout": "IPY_MODEL_22c90adf275445bf8d190d51c6bda958"
          }
        },
        "f22f7faddae9412483d88d0b98c3fc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5ce746d5466472e8558bd9a00ee72e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc5d66d247314e019247d1717c01fbf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2bab845abe4cd0b3374ab8c40c2e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdab33182583424693359d34fdef64f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff3feeb9a34f49e18694615448126891": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
